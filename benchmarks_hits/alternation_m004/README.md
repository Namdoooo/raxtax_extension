# Benchmark: Substitution Rate and Complementation

## Purpose
This benchmark evaluates whether the substitution rate of the query
sequences affects the ability of the extended raxtax workflow to handle
disoriented queries. Specifically, it investigates whether changes in
the substitution rate alter the performance gap between correctly
oriented and disoriented queries. This benchmark directory represents a 
partial experiment of the substitution rate and complementation study and 
evaluates the alternation effect for a single, fixed substitution rate.

## Benchmark Design
The benchmark consists of two top-level conditions:
- `oriented/`
- `disoriented/`

Each condition contains 30 iterations. Iteration *i* in the `oriented/`
directory is paired with iteration *i* in the `disoriented/` directory.
Paired iterations use identical input data and random seeds; the only
difference between them is the orientation of the query sequences.

All other parameters remain fixed across iterations and between the two
conditions.

## Data Generation
All input data used in this benchmark is generated automatically by the
benchmark scripts. No external input data is required.

For each iteration, configuration files defining the simulation
parameters and random seeds are generated once in the `oriented/`
directory. These configuration files are then copied to the
`disoriented/` directory to ensure that paired iterations use identical
datasets.

The `disoriented/` benchmark modifies the copied configuration files to
generate query sequences with unknown orientation, while keeping all
other parameters unchanged.

## Execution workflow
The benchmark execution is organized in multiple layers.

Each of the `oriented/` and `disoriented/` directories contains a
dedicated `main.py` file that orchestrates the execution of the 30
iterations for the respective condition.

Within each condition, iteration directories are created automatically.
Each iteration represents a single test run.

The execution proceeds as follows:

1. In the `oriented/` directory, configuration files are generated that
   define the simulation parameters and random seeds.
2. These configuration files are manually copied to the `disoriented/` 
   directory to establish a one-to-one pairing between oriented and disoriented
   iterations.
3. For each iteration, input data is generated based on the configuration
   file.
4. Executes the classification algorithm (raxtax extension) on the
   generated input data.

## How to Run
From the raxtax root directory, execute the oriented benchmark first to
generate the configuration files:

```
python -m benchmarks_hits.alternation_m004.oriented.main
```

Before executing this command, the line in
`benchmarks_hits/alternation_m004/oriented/main.py` that triggers the
execution of the classification algorithm must be commented out
(currently line 62). This ensures that only the configuration files are 
generated during this step.

Next, copy the generated configuration files from the `oriented/`
directory to the `disoriented/` directory to ensure identical random
seeds and input data for the paired tests.

Then execute the complete benchmark:

```
python -m benchmarks_hits.alternation_m004.main
```

After completion, analysis and plotting can be performed with:

```
python -m benchmarks_hits.alternation_m004.analyze
```

## Output

### Per iteration
For each iteration in both `oriented/` and `disoriented/` directories,
the following output is generated:

- `queries/`  
  Contains the generated query sequences used as input for the
  classification algorithm. This directory also includes intermediate
  files and log files produced during query generation.
- `references/`  
  Contains the generated reference data used for classification. This
  directory also includes intermediate files, log files, and a lookup
  table required by the classification algorithm.
- `results_*/`  
  Contains the classification results and a `metadata.out` file containing
  runtime measurements and classification statistics.

For archival purposes, the `queries/` and `references/` directories
generated by the benchmark were manually zipped together as
`dataset.tgz` to reduce storage requirements.

### After analysis
After executing the analysis scripts (`analyze.py`), 
the following additional output files are generated:

- `aggregated_metadata.csv`  
  Aggregated metadata for all tests within a single iteration.
- `combined_metadata.csv`  
  Aggregated metadata across all iterations.
- `significance_test.tsv`
  Contains the results of the Wilcoxon signed-rank test and effect size.

## Notes

The benchmark was executed using commit `6b9fc066cd644f4f09c3dfd7c22c2d10bcb65838` of the `raxtax_extension`
repository.

